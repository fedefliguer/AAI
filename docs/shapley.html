<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.9 Valores de Shapley | Aprendizaje automatico interpretable</title>
  <meta name="description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5.9 Valores de Shapley | Aprendizaje automatico interpretable" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.9 Valores de Shapley | Aprendizaje automatico interpretable" />
  
  <meta name="twitter:description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2021-01-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anchors.html"/>
<link rel="next" href="shap.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-159445204-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-159445204-1');
gtag('config', 'G-VCT0PH38N3');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "Este sitio usa cookies de Google Analytics para que pueda saber cuánta gente está leyendo el libro, y qué secciones son más populares. Este sitio no recolecta ningún dato personal."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="horadelcuento.html"><a href="horadelcuento.html"><i class="fa fa-check"></i><b>1.1</b> Hora del cuento</a><ul>
<li class="chapter" data-level="" data-path="horadelcuento.html"><a href="horadelcuento.html#un-rayo-nunca-golpea-dos-veces"><i class="fa fa-check"></i>Un rayo nunca golpea dos veces</a></li>
<li class="chapter" data-level="" data-path="horadelcuento.html"><a href="horadelcuento.html#perder-confianza"><i class="fa fa-check"></i>Perder confianza</a></li>
<li class="chapter" data-level="" data-path="horadelcuento.html"><a href="horadelcuento.html#clips-de-papel-de-fermi"><i class="fa fa-check"></i>Clips de papel de Fermi</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="qué-es-el-aprendizaje-automático.html"><a href="qué-es-el-aprendizaje-automático.html"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es el aprendizaje automático?</a></li>
<li class="chapter" data-level="1.3" data-path="terminología.html"><a href="terminología.html"><i class="fa fa-check"></i><b>1.3</b> Terminología</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretabilidad.html"><a href="interpretabilidad.html"><i class="fa fa-check"></i><b>2</b> Interpretabilidad</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretabilidad-importancia.html"><a href="interpretabilidad-importancia.html"><i class="fa fa-check"></i><b>2.1</b> Importancia de la interpretabilidad</a></li>
<li class="chapter" data-level="2.2" data-path="taxonomía-de-los-métodos-de-interpretación.html"><a href="taxonomía-de-los-métodos-de-interpretación.html"><i class="fa fa-check"></i><b>2.2</b> Taxonomía de los métodos de interpretación</a></li>
<li class="chapter" data-level="2.3" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html"><i class="fa fa-check"></i><b>2.3</b> Alcance de la interpretabilidad</a><ul>
<li class="chapter" data-level="2.3.1" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html#transparencia-del-algoritmo"><i class="fa fa-check"></i><b>2.3.1</b> Transparencia del algoritmo</a></li>
<li class="chapter" data-level="2.3.2" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html#interpretabilidad-global-y-holística-del-modelo"><i class="fa fa-check"></i><b>2.3.2</b> Interpretabilidad global y holística del modelo</a></li>
<li class="chapter" data-level="2.3.3" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html#interpretabilidad-del-modelo-global-en-un-nivel-modular"><i class="fa fa-check"></i><b>2.3.3</b> Interpretabilidad del modelo global en un nivel modular</a></li>
<li class="chapter" data-level="2.3.4" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html#interpretabilidad-local-para-una-única-predicción"><i class="fa fa-check"></i><b>2.3.4</b> Interpretabilidad local para una única predicción</a></li>
<li class="chapter" data-level="2.3.5" data-path="alcance-de-la-interpretabilidad.html"><a href="alcance-de-la-interpretabilidad.html#interpretabilidad-local-para-un-grupo-de-predicciones"><i class="fa fa-check"></i><b>2.3.5</b> Interpretabilidad local para un grupo de predicciones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluación-de-la-interpretabilidad.html"><a href="evaluación-de-la-interpretabilidad.html"><i class="fa fa-check"></i><b>2.4</b> Evaluación de la interpretabilidad</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> Propiedades de las explicaciones</a></li>
<li class="chapter" data-level="2.6" data-path="amigables.html"><a href="amigables.html"><i class="fa fa-check"></i><b>2.6</b> Explicaciones amigables para los humanos</a><ul>
<li class="chapter" data-level="2.6.1" data-path="amigables.html"><a href="amigables.html#qué-es-una-explicación"><i class="fa fa-check"></i><b>2.6.1</b> ¿Qué es una explicación?</a></li>
<li class="chapter" data-level="2.6.2" data-path="amigables.html"><a href="amigables.html#buenaexplicación"><i class="fa fa-check"></i><b>2.6.2</b> ¿Qué es una buena explicación?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conjuntosdedatos.html"><a href="conjuntosdedatos.html"><i class="fa fa-check"></i><b>3</b> Conjuntos de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Alquiler de bicicletas (Regresión)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> Comentarios de spam de YouTube (clasificación de texto)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> Factores de riesgo para el cáncer de cuello uterino (Clasificación)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Modelos interpretables</a><ul>
<li class="chapter" data-level="4.1" data-path="lineal.html"><a href="lineal.html"><i class="fa fa-check"></i><b>4.1</b> Regresión lineal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="lineal.html"><a href="lineal.html#interpretación"><i class="fa fa-check"></i><b>4.1.1</b> Interpretación</a></li>
<li class="chapter" data-level="4.1.2" data-path="lineal.html"><a href="lineal.html#ejemplo"><i class="fa fa-check"></i><b>4.1.2</b> Ejemplo</a></li>
<li class="chapter" data-level="4.1.3" data-path="lineal.html"><a href="lineal.html#interpretación-visual"><i class="fa fa-check"></i><b>4.1.3</b> Interpretación visual</a></li>
<li class="chapter" data-level="4.1.4" data-path="lineal.html"><a href="lineal.html#explicación-de-predicciones-individuales"><i class="fa fa-check"></i><b>4.1.4</b> Explicación de predicciones individuales</a></li>
<li class="chapter" data-level="4.1.5" data-path="lineal.html"><a href="lineal.html#categoricas"><i class="fa fa-check"></i><b>4.1.5</b> Codificación de características categóricas</a></li>
<li class="chapter" data-level="4.1.6" data-path="lineal.html"><a href="lineal.html#los-modelos-lineales-crean-buenas-explicaciones"><i class="fa fa-check"></i><b>4.1.6</b> ¿Los modelos lineales crean buenas explicaciones?</a></li>
<li class="chapter" data-level="4.1.7" data-path="lineal.html"><a href="lineal.html#lineales-dispersos"><i class="fa fa-check"></i><b>4.1.7</b> Modelos lineales dispersos</a></li>
<li class="chapter" data-level="4.1.8" data-path="lineal.html"><a href="lineal.html#ventajas"><i class="fa fa-check"></i><b>4.1.8</b> Ventajas</a></li>
<li class="chapter" data-level="4.1.9" data-path="lineal.html"><a href="lineal.html#desventajas"><i class="fa fa-check"></i><b>4.1.9</b> Desventajas</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logística.html"><a href="logística.html"><i class="fa fa-check"></i><b>4.2</b> Regresión logística</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logística.html"><a href="logística.html#qué-tiene-de-malo-la-regresión-lineal-para-la-clasificación"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué tiene de malo la regresión lineal para la clasificación?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logística.html"><a href="logística.html#teoría"><i class="fa fa-check"></i><b>4.2.2</b> Teoría</a></li>
<li class="chapter" data-level="4.2.3" data-path="logística.html"><a href="logística.html#interpretación-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretación</a></li>
<li class="chapter" data-level="4.2.4" data-path="logística.html"><a href="logística.html#ejemplo-1"><i class="fa fa-check"></i><b>4.2.4</b> Ejemplo</a></li>
<li class="chapter" data-level="4.2.5" data-path="logística.html"><a href="logística.html#ventajas-y-desventajas"><i class="fa fa-check"></i><b>4.2.5</b> Ventajas y desventajas</a></li>
<li class="chapter" data-level="4.2.6" data-path="logística.html"><a href="logística.html#software"><i class="fa fa-check"></i><b>4.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.3</b> GLM, GAM y más</a><ul>
<li class="chapter" data-level="4.3.1" data-path="extend-lm.html"><a href="extend-lm.html#GLM"><i class="fa fa-check"></i><b>4.3.1</b> Resultados no gaussianos: GLM</a></li>
<li class="chapter" data-level="4.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.3.2</b> Interacciones</a></li>
<li class="chapter" data-level="4.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.3.3</b> Efectos no lineales - GAM</a></li>
<li class="chapter" data-level="4.3.4" data-path="extend-lm.html"><a href="extend-lm.html#ventajas-1"><i class="fa fa-check"></i><b>4.3.4</b> Ventajas</a></li>
<li class="chapter" data-level="4.3.5" data-path="extend-lm.html"><a href="extend-lm.html#desventajas-1"><i class="fa fa-check"></i><b>4.3.5</b> Desventajas</a></li>
<li class="chapter" data-level="4.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>4.3.6</b> Software</a></li>
<li class="chapter" data-level="4.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.3.7</b> Extensiones adicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="arbol.html"><a href="arbol.html"><i class="fa fa-check"></i><b>4.4</b> Árbol de decisión</a><ul>
<li class="chapter" data-level="4.4.1" data-path="arbol.html"><a href="arbol.html#interpretación-2"><i class="fa fa-check"></i><b>4.4.1</b> Interpretación</a></li>
<li class="chapter" data-level="4.4.2" data-path="arbol.html"><a href="arbol.html#ejemplo-2"><i class="fa fa-check"></i><b>4.4.2</b> Ejemplo</a></li>
<li class="chapter" data-level="4.4.3" data-path="arbol.html"><a href="arbol.html#ventajas-2"><i class="fa fa-check"></i><b>4.4.3</b> Ventajas</a></li>
<li class="chapter" data-level="4.4.4" data-path="arbol.html"><a href="arbol.html#desventajas-2"><i class="fa fa-check"></i><b>4.4.4</b> Desventajas</a></li>
<li class="chapter" data-level="4.4.5" data-path="arbol.html"><a href="arbol.html#software-2"><i class="fa fa-check"></i><b>4.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="reglas.html"><a href="reglas.html"><i class="fa fa-check"></i><b>4.5</b> Reglas de decisión</a><ul>
<li class="chapter" data-level="4.5.1" data-path="reglas.html"><a href="reglas.html#aprender-las-reglas-de-una-sola-función-oner"><i class="fa fa-check"></i><b>4.5.1</b> Aprender las reglas de una sola función (OneR)</a></li>
<li class="chapter" data-level="4.5.2" data-path="reglas.html"><a href="reglas.html#cobertura-secuencial"><i class="fa fa-check"></i><b>4.5.2</b> Cobertura secuencial</a></li>
<li class="chapter" data-level="4.5.3" data-path="reglas.html"><a href="reglas.html#listas-de-reglas-bayesianas"><i class="fa fa-check"></i><b>4.5.3</b> Listas de reglas bayesianas</a></li>
<li class="chapter" data-level="4.5.4" data-path="reglas.html"><a href="reglas.html#ventajas-3"><i class="fa fa-check"></i><b>4.5.4</b> Ventajas</a></li>
<li class="chapter" data-level="4.5.5" data-path="reglas.html"><a href="reglas.html#desventajas-3"><i class="fa fa-check"></i><b>4.5.5</b> Desventajas</a></li>
<li class="chapter" data-level="4.5.6" data-path="reglas.html"><a href="reglas.html#software-y-alternativas"><i class="fa fa-check"></i><b>4.5.6</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.6</b> RuleFit</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretación-y-ejemplo"><i class="fa fa-check"></i><b>4.6.1</b> Interpretación y ejemplo</a></li>
<li class="chapter" data-level="4.6.2" data-path="rulefit.html"><a href="rulefit.html#teoría-1"><i class="fa fa-check"></i><b>4.6.2</b> Teoría</a></li>
<li class="chapter" data-level="4.6.3" data-path="rulefit.html"><a href="rulefit.html#ventajas-4"><i class="fa fa-check"></i><b>4.6.3</b> Ventajas</a></li>
<li class="chapter" data-level="4.6.4" data-path="rulefit.html"><a href="rulefit.html#desventajas-4"><i class="fa fa-check"></i><b>4.6.4</b> Desventajas</a></li>
<li class="chapter" data-level="4.6.5" data-path="rulefit.html"><a href="rulefit.html#software-y-alternativa"><i class="fa fa-check"></i><b>4.6.5</b> Software y alternativa</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="interpretables-otros.html"><a href="interpretables-otros.html"><i class="fa fa-check"></i><b>4.7</b> Otros modelos interpretables</a><ul>
<li class="chapter" data-level="4.7.1" data-path="interpretables-otros.html"><a href="interpretables-otros.html#clasificador-naive-bayes"><i class="fa fa-check"></i><b>4.7.1</b> Clasificador Naive Bayes</a></li>
<li class="chapter" data-level="4.7.2" data-path="interpretables-otros.html"><a href="interpretables-otros.html#k-vecinos-más-cercanos"><i class="fa fa-check"></i><b>4.7.2</b> K Vecinos más cercanos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostico.html"><a href="agnostico.html"><i class="fa fa-check"></i><b>5</b> Métodos modelo-agnósticos</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Diagrama de dependencia parcial (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#ejemplos"><i class="fa fa-check"></i><b>5.1.1</b> Ejemplos</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#ventajas-5"><i class="fa fa-check"></i><b>5.1.2</b> Ventajas</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#desventajas-5"><i class="fa fa-check"></i><b>5.1.3</b> Desventajas</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#software-y-alternativas-1"><i class="fa fa-check"></i><b>5.1.4</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ICE.html"><a href="ICE.html"><i class="fa fa-check"></i><b>5.2</b> Expectativa condicional individual (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ICE.html"><a href="ICE.html#ejemplos-1"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplos</a></li>
<li class="chapter" data-level="5.2.2" data-path="ICE.html"><a href="ICE.html#ventajas-6"><i class="fa fa-check"></i><b>5.2.2</b> Ventajas</a></li>
<li class="chapter" data-level="5.2.3" data-path="ICE.html"><a href="ICE.html#desventajas-6"><i class="fa fa-check"></i><b>5.2.3</b> Desventajas</a></li>
<li class="chapter" data-level="5.2.4" data-path="ICE.html"><a href="ICE.html#software-y-alternativas-2"><i class="fa fa-check"></i><b>5.2.4</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Gráfico de efectos locales acumulados (ALE)</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivación-e-intuición"><i class="fa fa-check"></i><b>5.3.1</b> Motivación e intuición</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#teoría-2"><i class="fa fa-check"></i><b>5.3.2</b> Teoría</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimación"><i class="fa fa-check"></i><b>5.3.3</b> Estimación</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#ejemplos-2"><i class="fa fa-check"></i><b>5.3.4</b> Ejemplos</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#ventajas-7"><i class="fa fa-check"></i><b>5.3.5</b> Ventajas</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#desventajas-7"><i class="fa fa-check"></i><b>5.3.6</b> Desventajas</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementación-y-alternativas"><i class="fa fa-check"></i><b>5.3.7</b> Implementación y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interacción.html"><a href="interacción.html"><i class="fa fa-check"></i><b>5.4</b> Interacción de características</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interacción.html"><a href="interacción.html#interacción-de-características"><i class="fa fa-check"></i><b>5.4.1</b> Interacción de características</a></li>
<li class="chapter" data-level="5.4.2" data-path="interacción.html"><a href="interacción.html#teoría-estadístico-h-de-friedman"><i class="fa fa-check"></i><b>5.4.2</b> Teoría: estadístico H de Friedman</a></li>
<li class="chapter" data-level="5.4.3" data-path="interacción.html"><a href="interacción.html#ejemplos-3"><i class="fa fa-check"></i><b>5.4.3</b> Ejemplos</a></li>
<li class="chapter" data-level="5.4.4" data-path="interacción.html"><a href="interacción.html#ventajas-8"><i class="fa fa-check"></i><b>5.4.4</b> Ventajas</a></li>
<li class="chapter" data-level="5.4.5" data-path="interacción.html"><a href="interacción.html#desventajas-8"><i class="fa fa-check"></i><b>5.4.5</b> Desventajas</a></li>
<li class="chapter" data-level="5.4.6" data-path="interacción.html"><a href="interacción.html#implementaciones"><i class="fa fa-check"></i><b>5.4.6</b> Implementaciones</a></li>
<li class="chapter" data-level="5.4.7" data-path="interacción.html"><a href="interacción.html#alternativas"><i class="fa fa-check"></i><b>5.4.7</b> Alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html"><i class="fa fa-check"></i><b>5.5</b> Importancia de la característica de permutación</a><ul>
<li class="chapter" data-level="5.5.1" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#teoría-3"><i class="fa fa-check"></i><b>5.5.1</b> Teoría</a></li>
<li class="chapter" data-level="5.5.2" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#importanciadecaracteristicas-datos"><i class="fa fa-check"></i><b>5.5.2</b> ¿Debo calcular la importancia de los datos de entrenamiento o prueba?</a></li>
<li class="chapter" data-level="5.5.3" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#ejemplo-e-interpretación"><i class="fa fa-check"></i><b>5.5.3</b> Ejemplo e interpretación</a></li>
<li class="chapter" data-level="5.5.4" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#ventajas-9"><i class="fa fa-check"></i><b>5.5.4</b> Ventajas</a></li>
<li class="chapter" data-level="5.5.5" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#desventajas-9"><i class="fa fa-check"></i><b>5.5.5</b> Desventajas</a></li>
<li class="chapter" data-level="5.5.6" data-path="importanciadecaracteristicas.html"><a href="importanciadecaracteristicas.html#software-y-alternativas-3"><i class="fa fa-check"></i><b>5.5.6</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Sustituto global</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#teoría-4"><i class="fa fa-check"></i><b>5.6.1</b> Teoría</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#ejemplo-4"><i class="fa fa-check"></i><b>5.6.2</b> Ejemplo</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#ventajas-10"><i class="fa fa-check"></i><b>5.6.3</b> Ventajas</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#desventajas-10"><i class="fa fa-check"></i><b>5.6.4</b> Desventajas</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-3"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Sustituto local (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-para-datos-tabulares"><i class="fa fa-check"></i><b>5.7.1</b> LIME para datos tabulares</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-para-texto"><i class="fa fa-check"></i><b>5.7.2</b> LIME para texto</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#imagenes-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME para imágenes</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#ventajas-11"><i class="fa fa-check"></i><b>5.7.4</b> Ventajas</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#desventajas-11"><i class="fa fa-check"></i><b>5.7.5</b> Desventajas</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.8</b> Reglas de ámbito (Anclas)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anchors.html"><a href="anchors.html#encontrar-anclas"><i class="fa fa-check"></i><b>5.8.1</b> Encontrar anclas</a></li>
<li class="chapter" data-level="5.8.2" data-path="anchors.html"><a href="anchors.html#complejidad-y-tiempo-de-ejecución"><i class="fa fa-check"></i><b>5.8.2</b> Complejidad y tiempo de ejecución</a></li>
<li class="chapter" data-level="5.8.3" data-path="anchors.html"><a href="anchors.html#ejemplo-de-datos-tabulares"><i class="fa fa-check"></i><b>5.8.3</b> Ejemplo de datos tabulares</a></li>
<li class="chapter" data-level="5.8.4" data-path="anchors.html"><a href="anchors.html#ventajas-12"><i class="fa fa-check"></i><b>5.8.4</b> Ventajas</a></li>
<li class="chapter" data-level="5.8.5" data-path="anchors.html"><a href="anchors.html#desventajas-12"><i class="fa fa-check"></i><b>5.8.5</b> Desventajas</a></li>
<li class="chapter" data-level="5.8.6" data-path="anchors.html"><a href="anchors.html#software-y-alternativas-4"><i class="fa fa-check"></i><b>5.8.6</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.9</b> Valores de Shapley</a><ul>
<li class="chapter" data-level="5.9.1" data-path="shapley.html"><a href="shapley.html#idea-general"><i class="fa fa-check"></i><b>5.9.1</b> Idea general</a></li>
<li class="chapter" data-level="5.9.2" data-path="shapley.html"><a href="shapley.html#ejemplos-e-interpretación"><i class="fa fa-check"></i><b>5.9.2</b> Ejemplos e interpretación</a></li>
<li class="chapter" data-level="5.9.3" data-path="shapley.html"><a href="shapley.html#el-valor-de-shapley-en-detalle"><i class="fa fa-check"></i><b>5.9.3</b> El valor de Shapley en detalle</a></li>
<li class="chapter" data-level="5.9.4" data-path="shapley.html"><a href="shapley.html#ventajas-13"><i class="fa fa-check"></i><b>5.9.4</b> Ventajas</a></li>
<li class="chapter" data-level="5.9.5" data-path="shapley.html"><a href="shapley.html#desventajas-13"><i class="fa fa-check"></i><b>5.9.5</b> Desventajas</a></li>
<li class="chapter" data-level="5.9.6" data-path="shapley.html"><a href="shapley.html#software-y-alternativas-5"><i class="fa fa-check"></i><b>5.9.6</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.10</b> SHAP (explicaciones aditivas SHapley)</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shap.html"><a href="shap.html#definición"><i class="fa fa-check"></i><b>5.10.1</b> Definición</a></li>
<li class="chapter" data-level="5.10.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.10.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.10.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.10.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.10.4" data-path="shap.html"><a href="shap.html#ejemplos-4"><i class="fa fa-check"></i><b>5.10.4</b> Ejemplos</a></li>
<li class="chapter" data-level="5.10.5" data-path="shap.html"><a href="shap.html#importancia-de-la-función-shap"><i class="fa fa-check"></i><b>5.10.5</b> Importancia de la función SHAP</a></li>
<li class="chapter" data-level="5.10.6" data-path="shap.html"><a href="shap.html#gráfico-de-resumen-shap"><i class="fa fa-check"></i><b>5.10.6</b> Gráfico de resumen SHAP</a></li>
<li class="chapter" data-level="5.10.7" data-path="shap.html"><a href="shap.html#shap-gráfico-de-dependencia"><i class="fa fa-check"></i><b>5.10.7</b> SHAP Gráfico de dependencia</a></li>
<li class="chapter" data-level="5.10.8" data-path="shap.html"><a href="shap.html#valores-de-interacción-shap"><i class="fa fa-check"></i><b>5.10.8</b> Valores de interacción SHAP</a></li>
<li class="chapter" data-level="5.10.9" data-path="shap.html"><a href="shap.html#agrupando-valores-shap"><i class="fa fa-check"></i><b>5.10.9</b> Agrupando valores SHAP</a></li>
<li class="chapter" data-level="5.10.10" data-path="shap.html"><a href="shap.html#ventajas-14"><i class="fa fa-check"></i><b>5.10.10</b> Ventajas</a></li>
<li class="chapter" data-level="5.10.11" data-path="shap.html"><a href="shap.html#desventajas-14"><i class="fa fa-check"></i><b>5.10.11</b> Desventajas</a></li>
<li class="chapter" data-level="5.10.12" data-path="shap.html"><a href="shap.html#software-4"><i class="fa fa-check"></i><b>5.10.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basadoenejemplos.html"><a href="basadoenejemplos.html"><i class="fa fa-check"></i><b>6</b> Explicaciones basadas en ejemplos</a><ul>
<li class="chapter" data-level="6.1" data-path="contrafactual.html"><a href="contrafactual.html"><i class="fa fa-check"></i><b>6.1</b> Explicaciones contrafácticas</a><ul>
<li class="chapter" data-level="6.1.1" data-path="contrafactual.html"><a href="contrafactual.html#generando-explicaciones-contrafácticas"><i class="fa fa-check"></i><b>6.1.1</b> Generando explicaciones contrafácticas</a></li>
<li class="chapter" data-level="6.1.2" data-path="contrafactual.html"><a href="contrafactual.html#ejemplos-5"><i class="fa fa-check"></i><b>6.1.2</b> Ejemplos</a></li>
<li class="chapter" data-level="6.1.3" data-path="contrafactual.html"><a href="contrafactual.html#ventajas-15"><i class="fa fa-check"></i><b>6.1.3</b> Ventajas</a></li>
<li class="chapter" data-level="6.1.4" data-path="contrafactual.html"><a href="contrafactual.html#desventajas-15"><i class="fa fa-check"></i><b>6.1.4</b> Desventajas</a></li>
<li class="chapter" data-level="6.1.5" data-path="contrafactual.html"><a href="contrafactual.html#ejemplo-software"><i class="fa fa-check"></i><b>6.1.5</b> Software y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Ejemplos adversos</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#métodos-y-ejemplos"><i class="fa fa-check"></i><b>6.2.1</b> Métodos y ejemplos</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#la-perspectiva-de-ciberseguridad"><i class="fa fa-check"></i><b>6.2.2</b> La perspectiva de ciberseguridad</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototipos y excepciones</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#teoría-5"><i class="fa fa-check"></i><b>6.3.1</b> Teoría</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#ejemplos-6"><i class="fa fa-check"></i><b>6.3.2</b> Ejemplos</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#ventajas-16"><i class="fa fa-check"></i><b>6.3.3</b> Ventajas</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#desventajas-16"><i class="fa fa-check"></i><b>6.3.4</b> Desventajas</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#código-y-alternativas"><i class="fa fa-check"></i><b>6.3.5</b> Código y alternativas</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influyente.html"><a href="influyente.html"><i class="fa fa-check"></i><b>6.4</b> Instancias influyentes</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influyente.html"><a href="influyente.html#diagnóstico-de-eliminación"><i class="fa fa-check"></i><b>6.4.1</b> Diagnóstico de eliminación</a></li>
<li class="chapter" data-level="6.4.2" data-path="influyente.html"><a href="influyente.html#funciones-de-influencia"><i class="fa fa-check"></i><b>6.4.2</b> Funciones de influencia</a></li>
<li class="chapter" data-level="6.4.3" data-path="influyente.html"><a href="influyente.html#ventajas-de-identificar-instancias-influyentes"><i class="fa fa-check"></i><b>6.4.3</b> Ventajas de identificar instancias influyentes</a></li>
<li class="chapter" data-level="6.4.4" data-path="influyente.html"><a href="influyente.html#desventajas-de-identificar-instancias-influyentes"><i class="fa fa-check"></i><b>6.4.4</b> Desventajas de identificar instancias influyentes</a></li>
<li class="chapter" data-level="6.4.5" data-path="influyente.html"><a href="influyente.html#software-y-alternativas-6"><i class="fa fa-check"></i><b>6.4.5</b> Software y alternativas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="redes-neuronales.html"><a href="redes-neuronales.html"><i class="fa fa-check"></i><b>7</b> Interpretación de redes neuronales</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Características aprendidas</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#visualización-características"><i class="fa fa-check"></i><b>7.1.1</b> Visualización de características</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#disección-red"><i class="fa fa-check"></i><b>7.1.2</b> Disección de red</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#ventajas-17"><i class="fa fa-check"></i><b>7.1.3</b> Ventajas</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#desventajas-17"><i class="fa fa-check"></i><b>7.1.4</b> Desventajas</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-y-material-adicional"><i class="fa fa-check"></i><b>7.1.5</b> Software y material adicional</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="futuro.html"><a href="futuro.html"><i class="fa fa-check"></i><b>8</b> Una mirada a la bola de cristal</a><ul>
<li class="chapter" data-level="8.1" data-path="el-futuro-del-aprendizaje-automático.html"><a href="el-futuro-del-aprendizaje-automático.html"><i class="fa fa-check"></i><b>8.1</b> El futuro del aprendizaje automático</a></li>
<li class="chapter" data-level="8.2" data-path="el-futuro-de-la-interpretabilidad.html"><a href="el-futuro-de-la-interpretabilidad.html"><i class="fa fa-check"></i><b>8.2</b> El futuro de la interpretabilidad</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribuir al libro</a></li>
<li class="chapter" data-level="10" data-path="cita.html"><a href="cita.html"><i class="fa fa-check"></i><b>10</b> Citando este libro</a></li>
<li class="chapter" data-level="11" data-path="traducciones.html"><a href="traducciones.html"><i class="fa fa-check"></i><b>11</b> Traducciones</a></li>
<li class="chapter" data-level="12" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i><b>12</b> Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used-for-examples.html"><a href="r-packages-used-for-examples.html"><i class="fa fa-check"></i>R Packages Used for Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje automatico interpretable</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="shapley" class="section level2">
<h2><span class="header-section-number">5.9</span> Valores de Shapley</h2>
<p>Una predicción puede explicarse suponiendo que cada valor de característica de la instancia es un “jugador” en un juego donde la predicción es el pago.
Los valores de Shapley, un método de la teoría de juegos de coalición, nos dicen cómo distribuir equitativamente el “pago” entre las características.</p>
<div id="idea-general" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Idea general</h3>
<p>Supón el siguiente escenario:</p>
<p>Has entrenado un modelo de aprendizaje automático para predecir los precios de los apartamentos.
Para un determinado apartamento predice €300,000 y necesitas explicar esta predicción.
El apartamento tiene un tamaño de 50 m<sup>2</sup>, está ubicado en el segundo piso, tiene un parque cercano y los gatos están prohibidos:</p>
<div class="figure"><span id="fig:shapley-instance"></span>
<img src="images/shapley-instance.png" alt="El precio previsto para un apartamento de 50 m^2^ en el segundo piso con un parque cercano y prohibición de gatos es de €300,000. Nuestro objetivo es explicar cómo cada uno de estos valores de características contribuyó a la predicción" width="500" />
<p class="caption">
FIGURA 5.42: El precio previsto para un apartamento de 50 m<sup>2</sup> en el segundo piso con un parque cercano y prohibición de gatos es de €300,000. Nuestro objetivo es explicar cómo cada uno de estos valores de características contribuyó a la predicción
</p>
</div>
<p>La predicción promedio para todos los apartamentos es de €310,000.
¿Cuánto ha contribuido cada valor de característica a la predicción en comparación con la predicción promedio?</p>
<p>La respuesta es simple para los modelos de regresión lineal.
El efecto de cada característica es el peso de la característica multiplicado por el valor de la característica.
Esto solo funciona debido a la linealidad del modelo.
Para modelos más complejos, necesitamos una solución diferente.
Por ejemplo, <a href="lime.html#lime">LIME</a> sugiere modelos locales para estimar los efectos.
Otra solución proviene de la teoría del juego cooperativo:
El valor de Shapley, acuñado por Shapley (1953)<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a>, es un método para asignar pagos a los jugadores en función de su contribución al pago total.
Los jugadores cooperan en una coalición y reciben una cierta ganancia de esta cooperación.</p>
<p>¿Jugadores?
¿Juego?
¿Pagar?
¿Cuál es la conexión con las predicciones e interpretabilidad del aprendizaje automático?
El “juego” es la tarea de predicción para una sola instancia del conjunto de datos.
La “ganancia” es la predicción real para esta instancia menos la predicción promedio para todas las instancias.
Los “jugadores” son las características de la instancia que colaboran para recibir la ganancia (= predecir un cierto valor).
En nuestro ejemplo de apartamento, los valores de la característica <code>parque-cerca</code>, <code>gato-prohibido</code>, <code>area-50</code> y <code>piso-2</code> trabajaron juntos para lograr la predicción de €300,000.
Nuestro objetivo es explicar la diferencia entre la predicción real (€300,000) y la predicción promedio (€310,000): una diferencia de -€10,000.</p>
<p>La respuesta podría ser:
El <code>parque-cerca</code> contribuyó con €30,000; <code>area-50</code> contribuyó con €10.000; <code>piso-2</code> contribuyó con €0; <code>gato-prohibido</code> contribuyó -€50,000.
Las contribuciones suman -€10,000, la predicción final menos el precio promedio previsto del apartamento.</p>
<p><strong>¿Cómo calculamos el valor de Shapley para una característica?</strong></p>
<p>El valor de Shapley es la contribución marginal promedio de un valor de característica en todas las coaliciones posibles.
Más claro ahora?</p>
<p>En la siguiente figura, evaluamos la contribución del valor de la característica <code>gato-prohibido</code> cuando se agrega a una coalición de <code>parque-cerca</code> y <code>area-50</code>.
Simulamos que solo <code>parque-cerca</code>, <code>gato-prohibido</code> y <code>area-50</code> están en una coalición extrayendo aleatoriamente otro departamento de los datos y usando su valor para el atributo piso.
El valor <code>piso-2</code> fue reemplazado por el aleatorio dibujado <code>piso-1</code>.
Luego predecimos el precio del apartamento con esta combinación (€ 310,000).
En un segundo paso, eliminamos <code>gato-prohibido</code> de la coalición reemplazándolo con un valor aleatorio de la característica gato prohibido/permitido del departamento dibujado al azar.
En el ejemplo estaba permitido, pero podría ser prohibido nuevamente.
Predecimos el precio del apartamento para la coalición de <code>parque cercano</code> y <code>tamaño-50</code> (€320,000).
La contribución de <code>gato prohibido</code> fue de €310,000 - €320,000 = - € 10,000.
Esta estimación depende de los valores del apartamento dibujado al azar que sirvió como “donante” para los valores de características de gato y piso.
Obtendremos mejores estimaciones si repetimos este paso de muestreo y promediamos las contribuciones.</p>
<div class="figure"><span id="fig:shapley-instance-intervened"></span>
<img src="images/shapley-instance-intervention.png" alt="Una repetición de muestra para estimar la contribución de `gato-prohibido` a la predicción cuando se agrega a la coalición de 'parque-cerca` y `area-50`." width="500" />
<p class="caption">
FIGURA 5.43: Una repetición de muestra para estimar la contribución de <code>gato-prohibido</code> a la predicción cuando se agrega a la coalición de ’parque-cerca<code>y</code>area-50`.
</p>
</div>
<p>Repetimos este cálculo para todas las coaliciones posibles.
El valor de Shapley es el promedio de todas las contribuciones marginales a todas las coaliciones posibles.
El tiempo de cálculo aumenta exponencialmente con el número de características.
Una solución para mantener manejable el tiempo de cálculo es calcular las contribuciones solo para unas pocas muestras de las posibles coaliciones.</p>
<p>La siguiente figura muestra todas las coaliciones de valores de características que se necesitan para determinar el valor de Shapley para <code>gato-prohibido</code>.
La primera fila muestra la coalición sin ningún valor de característica.
En la imagen, las filas segunda, tercera y cuarta muestran diferentes coaliciones con un tamaño de coalición creciente, separadas por “|”.
En general, son posibles las siguientes coaliciones:</p>
<ul>
<li><code>Sin valores de características</code></li>
<li><code>parque-cerca</code></li>
<li><code>area-50</code></li>
<li><code>piso-2</code></li>
<li><code>parque-cerca</code> + <code>area-50</code></li>
<li><code>parque-cerca</code> + <code>piso-2</code></li>
<li><code>area-50</code> + <code>piso-2</code></li>
<li><code>parque-cerca</code> + <code>area-50</code> + <code>piso-2</code></li>
</ul>
<p>Para cada una de estas coaliciones, calculamos el precio predicho del apartamento con y sin el valor de característica <code>gatos prohibidos</code> y tomamos la diferencia para obtener la contribución marginal.
El valor de Shapley es el promedio (ponderado) de las contribuciones marginales.
Reemplazamos los valores de características de las características que no están en una coalición con valores de características aleatorias del conjunto de datos del departamento para obtener una predicción del modelo de aprendizaje automático.</p>
<div class="figure"><span id="fig:shapley-coalitions"></span>
<img src="images/shapley-coalitions.png" alt="Las 8 coaliciones necesarias para calcular el valor exacto de Shapley del valor de la característica `gatos-prohibidos`." width="500" />
<p class="caption">
FIGURA 5.44: Las 8 coaliciones necesarias para calcular el valor exacto de Shapley del valor de la característica <code>gatos-prohibidos</code>.
</p>
</div>
<p>Si estimamos los valores de Shapley para todos los valores de características, obtenemos la distribución completa de la predicción (menos el promedio) entre los valores de características.</p>
</div>
<div id="ejemplos-e-interpretación" class="section level3">
<h3><span class="header-section-number">5.9.2</span> Ejemplos e interpretación</h3>
<p>La interpretación del valor de Shapley para el valor de característica j es:
El valor de la característica j contribuyó <span class="math inline">\(\phi_j\)</span> a la predicción de esta instancia particular en comparación con la predicción promedio para el conjunto de datos.</p>
<p>El valor de Shapley funciona tanto para la clasificación (si se trata de probabilidades) como para la regresión.</p>
<p>Utilizamos el valor de Shapley para analizar las predicciones de un random forest aleatorio que predice <a href="cervical.html#cervical">cáncer cervical</a>:</p>
<div class="figure"><span id="fig:shapley-cervical-plot"></span>
<img src="images/shapley-cervical-plot-1.png" alt="Valores de Shapley para una mujer en el conjunto de datos de cáncer cervical. Con una predicción de 0.53, la probabilidad de cáncer de esta mujer es 0.51 por encima de la predicción promedio de 0.03. El número de ETS diagnosticadas aumentó la probabilidad más. La suma de las contribuciones produce la diferencia entre la predicción real y la media (0.51)" width="1050" />
<p class="caption">
FIGURA 5.45: Valores de Shapley para una mujer en el conjunto de datos de cáncer cervical. Con una predicción de 0.53, la probabilidad de cáncer de esta mujer es 0.51 por encima de la predicción promedio de 0.03. El número de ETS diagnosticadas aumentó la probabilidad más. La suma de las contribuciones produce la diferencia entre la predicción real y la media (0.51)
</p>
</div>
<p>Para el <a href="bike-data.html#bike-data">conjunto de datos de alquiler de bicicletas</a>, también entrenamos un random forest para predecir el número de bicicletas alquiladas por un día, dada la información del clima y el calendario.
Las explicaciones creadas para la predicción aleatoria del random forest de un día en particular:</p>
<div class="figure"><span id="fig:shapley-bike-plot"></span>
<img src="images/shapley-bike-plot-1.png" alt="Valores de Shapley para el día 285. Con un número previsto de 2475 bicicletas alquiladas, este día está -2041 por debajo de la predicción promedio de 4516. la situación climática y la humedad tuvieron las mayores contribuciones negativas. La temperatura en este día tuvo una contribución positiva. La suma de los valores de Shapley produce la diferencia de predicción real y promedio (-2041)." width="1050" />
<p class="caption">
FIGURA 5.46: Valores de Shapley para el día 285. Con un número previsto de 2475 bicicletas alquiladas, este día está -2041 por debajo de la predicción promedio de 4516. la situación climática y la humedad tuvieron las mayores contribuciones negativas. La temperatura en este día tuvo una contribución positiva. La suma de los valores de Shapley produce la diferencia de predicción real y promedio (-2041).
</p>
</div>
<p>Ten cuidado de interpretar el valor de Shapley correctamente:
El valor de Shapley es la contribución promedio de un valor de característica a la predicción en diferentes coaliciones.
El valor de Shapley NO es la diferencia en la predicción cuando eliminaríamos la característica del modelo.</p>
</div>
<div id="el-valor-de-shapley-en-detalle" class="section level3">
<h3><span class="header-section-number">5.9.3</span> El valor de Shapley en detalle</h3>
<p>Esta sección profundiza en la definición y el cálculo del valor de Shapley para el lector curioso.
Omite esta sección y ve directamente a “Ventajas y desventajas” si no estás interesado en los detalles técnicos.</p>
<p>Estamos interesados en cómo cada característica afecta la predicción de un punto de datos.
En un modelo lineal es fácil calcular los efectos individuales.
Así es como se ve una predicción de modelo lineal para una instancia de datos:</p>
<p><span class="math display">\[\hat{f}(x)=\beta_0+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}\]</span></p>
<p>donde x es la instancia para la que queremos calcular las contribuciones.
Cada <span class="math inline">\(x_j\)</span> es un valor de característica, con j = 1, …, p.
<span class="math inline">\(\beta_j\)</span> es el peso correspondiente al atributo j.</p>
<p>La contribución <span class="math inline">\(\phi_j\)</span> de la función j-ésima en la predicción <span class="math inline">\(\hat{f}(x)\)</span> es:</p>
<p><span class="math display">\[\phi_j(\hat{f})=\beta_{j}x_j-E(\beta_{j}X_{j})=\beta_{j}x_j-\beta_{j}E(X_{j})\]</span></p>
<p>donde <span class="math inline">\(E(\beta_jX_{j})\)</span> es la estimación del efecto medio para la característica j.
La contribución es la diferencia entre el efecto de la característica menos el efecto promedio.
¡Agradable!
Ahora sabemos cuánto contribuyó cada característica a la predicción.
Si sumamos todas las contribuciones de características para una instancia, el resultado es el siguiente:</p>
<p><span class="math display">\[\begin{align*}\sum_{j=1}^{p}\phi_j(\hat{f})=&amp;\sum_{j=1}^p(\beta_{j}x_j-E(\beta_{j}X_{j}))\\=&amp;(\beta_0+\sum_{j=1}^p\beta_{j}x_j)-(\beta_0+\sum_{j=1}^{p}E(\beta_{j}X_{j}))\\=&amp;\hat{f}(x)-E(\hat{f}(X))\end{align*}\]</span></p>
<p>Este es el valor predicho para el punto de datos x menos el valor promedio predicho.
Las contribuciones de funciones pueden ser negativas.</p>
<p>¿Podemos hacer lo mismo para cualquier tipo de modelo?
Sería genial tener esto como una herramienta independiente del modelo.
Como generalmente no tenemos pesos similares en otros tipos de modelos, necesitamos una solución diferente.</p>
<p>La ayuda proviene de lugares inesperados: teoría de juegos cooperativos.
El valor Shapley es una solución para calcular las contribuciones de características para predicciones individuales para cualquier modelo de aprendizaje automático.</p>
<div id="el-valor-de-shapley" class="section level4">
<h4><span class="header-section-number">5.9.3.1</span> El valor de Shapley</h4>
<p>El valor de Shapley se define mediante una función de valor val de jugadores en S.</p>
<p>El valor de Shapley de un valor de característica es su contribución al pago, ponderado y sumado sobre todas las combinaciones posibles de valor de característica:</p>
<p><span class="math display">\[\phi_j(val)=\sum_{S\subseteq\{x_{1},\ldots,x_{p}\}\setminus\{x_j\}}\frac{|S|!\left(p-|S|-1\right)!}{p!}\left(val\left(S\cup\{x_j\}\right)-val(S)\right)\]</span></p>
<p>donde S es un subconjunto de las características utilizadas en el modelo, x es el vector de valores de características de la instancia a explicar y p el número de características.
<span class="math inline">\(val_x(S)\)</span> es la predicción para los valores de características en el conjunto S que están marginados sobre las características que no están incluidas en el conjunto S:</p>
<p><span class="math display">\[val_{x}(S)=\int\hat{f}(x_{1},\ldots,x_{p})d\mathbb{P}_{x\notin{}S}-E_X(\hat{f}(X))\]</span></p>
<p>Realmente realiza múltiples integraciones para cada característica que no está contenida S.
Un ejemplo concreto:
El modelo de aprendizaje automático funciona con 4 características x1, x2, x3 y x4 y evaluamos la predicción para la coalición S que consta de valores de características x1 y x3:</p>
<p><span class="math display">\[val_{x}(S)=val_{x}(\{x_{1},x_{3}\})=\int_{\mathbb{R}}\int_{\mathbb{R}}\hat{f}(x_{1},X_{2},x_{3},X_{4})d\mathbb{P}_{X_2X_4}-E_X(\hat{f}(X))\]</span></p>
<p>¡Esto se parece a las contribuciones de características en el modelo lineal!</p>
<p>No lo confudas con los muchos usos de la palabra “valor”:
El valor de la característica es el valor numérico o categórico de una característica e instancia;
el valor de Shapley es la contribución de la característica a la predicción;
la función de valor es la función de pago para coaliciones de jugadores (valores de características).</p>
<p>El valor de Shapley es el único método de atribución que satisface las propiedades <strong>Eficiencia</strong>, <strong>Simetría</strong>, <strong>Dummies</strong> y <strong>Aditividad</strong>, que juntas pueden considerarse una definición de pago justo.</p>
<p><strong>Eficiencia</strong><br />
Las contribuciones de características deben sumarse a la diferencia de predicción para x y el promedio.</p>
<p><span class="math display">\[\sum\nolimits_{j=1}^p\phi_j=\hat{f}(x)-E_X(\hat{f}(X))\]</span></p>
<p><strong>Simetría</strong><br />
Las contribuciones de dos valores de características j y k deberían ser las mismas si contribuyen igualmente a todas las coaliciones posibles.
Si</p>
<p><span class="math display">\[val(S\cup\{x_j\})=val(S\cup\{x_k\})\]</span></p>
<p>para todos</p>
<p><span class="math display">\[S\subseteq\{x_{1},\ldots,x_{p}\}\setminus\{x_j,x_k\}\]</span></p>
<p>luego</p>
<p><span class="math display">\[\phi_j=\phi_{k}\]</span></p>
<p><strong>Dummies</strong><br />
Una característica j que no cambia el valor predicho, independientemente de a qué coalición de valores de característica se agregue, debe tener un valor Shapley de 0.
Si</p>
<p><span class="math display">\[val(S\cup\{x_j\})=val(S)\]</span></p>
<p>para todos</p>
<p><span class="math display">\[S\subseteq\{x_{1},\ldots,x_{p}\}\]</span></p>
<p>luego</p>
<p><span class="math display">\[\phi_j=0\]</span></p>
<p><strong>Aditividad</strong><br />
Para un juego con pagos combinados val+val<sup>+</sup>, los valores de Shapley respectivos son los siguientes:</p>
<p><span class="math display">\[\phi_j+\phi_j^{+}\]</span></p>
<p>Supongamos que entrenaste un random forest, lo que significa que la predicción es un promedio de muchos árboles de decisión.
La propiedad Aditividad garantiza que para un valor de característica, puedes calcular el valor de Shapley para cada árbol individualmente, promediarlos y obtener el valor de Shapley para el valor de característica para el random forest.</p>
</div>
<div id="intuición" class="section level4">
<h4><span class="header-section-number">5.9.3.2</span> Intuición</h4>
<p>Una forma intuitiva de comprender el valor de Shapley es la siguiente ilustración:
Los valores de las características ingresan a una habitación en orden aleatorio.
Todos los valores de características en la sala participan en el juego (= contribuyen a la predicción).
El valor de Shapley de un valor de característica es el cambio promedio en la predicción que la coalición que ya está en la sala recibe cuando el valor de característica se une a ellos.</p>
</div>
<div id="estimación-del-valor-de-shapley" class="section level4">
<h4><span class="header-section-number">5.9.3.3</span> Estimación del valor de Shapley</h4>
<p>Todas las coaliciones (conjuntos) posibles de valores de características deben evaluarse con y sin la característica j-ésima para calcular el valor exacto de Shapley.
Para más de unas pocas características, la solución exacta a este problema se vuelve problemática ya que el número de coaliciones posibles aumenta exponencialmente a medida que se agregan más características.
Strumbelj et al. (2014)<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a> proponen una aproximación con el muestreo de Monte-Carlo:</p>
<p><span class="math display">\[\hat{\phi}_{j}=\frac{1}{M}\sum_{m=1}^M\left(\hat{f}(x^{m}_{+j})-\hat{f}(x^{m}_{-j})\right)\]</span></p>
<p>donde <span class="math inline">\(\hat{f}(x^{m}_{+j})\)</span> es la predicción para x, pero con un número aleatorio de valores de características reemplazados por valores de características de un punto de datos aleatorio z, excepto el valor respectivo de la característica j.
El vector x <span class="math inline">\(x^{m}_{-j}\)</span> es casi idéntico a <span class="math inline">\(x^{m}_{+j}\)</span>, pero el valor <span class="math inline">\(x_j^{m}\)</span> también se toma de la muestra z.
Cada una de estas M nuevas instancias es una especie de “Frankenstein” ensamblado a partir de dos instancias.</p>
<p><strong>Estimación aproximada de Shapley para el valor de una sola característica</strong>:</p>
<ul>
<li>Salida: valor de Shapley para el valor de la característica j-ésima</li>
<li>Requerido: Número de iteraciones M, instancia de interés x, índice de características j, matriz de datos X y modelo de aprendizaje automático f
  - Para todos m = 1, …, M:
<ul>
<li>Dibuja una instancia aleatoria z de la matriz de datos X</li>
<li>Elige una permutación aleatoria de los valores de la característica</li>
<li>Instancia de pedido x: <span class="math inline">\(x_o=(x_{(1)},\ldots,x_{(j)},\ldots,x_{(p)})\)</span></li>
<li>Instancia de pedido z: <span class="math inline">\(z_o=(z_{(1)},\ldots,z_{(j)},\ldots,z_{(p)})\)</span></li>
<li>Construye dos nuevas instancias
<ul>
<li>Con la función j: <span class="math inline">\(x_{+j}=(x_{(1)},\ldots,x_{(j-1)},x_{(j)},z_{(j+1)},\ldots,z_{(p)})\)</span></li>
<li>Sin la característica j: <span class="math inline">\(x_{-j}=(x_{(1)},\ldots,x_{(j-1)},z_{(j)},z_{(j+1)},\ldots,z_{(p)})\)</span></li>
</ul></li>
<li>Calcular contribución marginal: <span class="math inline">\(\phi_j^{m}=\hat{f}(x_{+j})-\hat{f}(x_{-j})\)</span></li>
</ul></li>
<li>Calcular el valor de Shapley como el promedio: <span class="math inline">\(\phi_j(x)=\frac{1}{M}\sum_{m=1}^M\phi_j^{m}\)</span></li>
</ul>
<p>Primero, selecciona una instancia de interés x, una característica j y el número de iteraciones M.
Para cada iteración, se selecciona una instancia aleatoria z de los datos y se genera un orden aleatorio de las características.
Se crean dos nuevas instancias combinando valores de la instancia de interés x y la muestra z.
La primera instancia <span class="math inline">\(x_{+j}\)</span> es la instancia de interés, pero todos los valores en el orden anterior e incluido el valor de la característica j se reemplazan por los valores de la característica de la muestra z.
La segunda instancia <span class="math inline">\(x_{-j}\)</span> es similar, pero tiene todos los valores en el orden anterior, pero excluye la característica j reemplazada por los valores de la característica j de la muestra z.
Se calcula la diferencia en la predicción de caja negra:</p>
<p><span class="math display">\[\phi_j^{m}=\hat{f}(x^m_{+j})-\hat{f}(x^m_{-j})\]</span></p>
<p>Todas estas diferencias se promedian y dan como resultado:</p>
<p><span class="math display">\[\phi_j(x)=\frac{1}{M}\sum_{m=1}^M\phi_j^{m}\]</span></p>
<p>El promedio pesa implícitamente las muestras por la distribución de probabilidad de X.</p>
<p>El procedimiento debe repetirse para cada una de las características para obtener todos los valores de Shapley.</p>
</div>
</div>
<div id="ventajas-13" class="section level3">
<h3><span class="header-section-number">5.9.4</span> Ventajas</h3>
<p>La diferencia entre la predicción y la predicción promedio está <strong>distribuida de manera justa</strong> entre los valores de característica de la instancia: la propiedad de eficiencia de los valores de Shapley.
Esta propiedad distingue el valor Shapley de otros métodos como <a href="lime.html#lime">LIME</a>.
LIME no garantiza que la predicción se distribuya equitativamente entre las características.
El valor de Shapley podría ser el único método para entregar una explicación completa.
En situaciones donde la ley requiere explicabilidad, como el “derecho a explicaciones” de la UE, el valor de Shapley podría ser el único método legalmente compatible, porque se basa en una teoría sólida y distribuye los efectos de manera justa.
No soy abogado, así que esto refleja solo mi intuición sobre los requisitos.</p>
<p>El valor de Shapley permite <strong>explicaciones contrastantes</strong>.
En lugar de comparar una predicción con la predicción promedio de todo el conjunto de datos, puedes compararla con un subconjunto o incluso con un único punto de datos.
Este contraste también es algo que los modelos locales como LIME no tienen.</p>
<p>El valor de Shapley es el único método de explicación con una <strong>teoría sólida</strong>.
Los axiomas (eficiencia, simetría, dummies, aditividad) dan a la explicación una base razonable.
Métodos como LIME suponen un comportamiento lineal del modelo de aprendizaje automático a nivel local, pero no hay una teoría de por qué esto debería funcionar.</p>
<p>Es alucinante <strong>explicar una predicción como un juego</strong> jugado por los valores de las características.</p>
</div>
<div id="desventajas-13" class="section level3">
<h3><span class="header-section-number">5.9.5</span> Desventajas</h3>
<p>El valor de Shapley requiere <strong>mucho tiempo de cómputo</strong>.
En el 99.9% de los problemas del mundo real, solo la solución aproximada es factible.
Un cálculo exacto del valor de Shapley es computacionalmente costoso porque hay 2<sup>k</sup> posibles coaliciones de los valores de la característica y la “ausencia” de una característica tiene que ser simulada dibujando instancias aleatorias, lo que aumenta la varianza para la estimación de Shapley estimación de valores.
El número exponencial de las coaliciones se trata muestreando coaliciones y limitando el número de iteraciones M.
La disminución de M reduce el tiempo de cálculo, pero aumenta la varianza del valor de Shapley.
No hay una buena regla general para el número de iteraciones M.
M debe ser lo suficientemente grande como para estimar con precisión los valores de Shapley, pero lo suficientemente pequeño como para completar el cálculo en un tiempo razonable.
Debería ser posible elegir M en función de los límites de Chernoff, pero no he visto ningún documento sobre cómo hacer esto para los valores de Shapley para las predicciones de aprendizaje automático.</p>
<p>El valor de Shapley <strong>puede malinterpretarse</strong>.
El valor de Shapley de un valor de característica no es la diferencia del valor pronosticado después de eliminar la característica del entrenamiento del modelo.
La interpretación del valor de Shapley es:
Dado el conjunto actual de valores de características, la contribución de un valor de característica a la diferencia entre la predicción real y la predicción media es el valor estimado de Shapley.</p>
<p>El valor de Shapley es el método de explicación incorrecto si busca explicaciones dispersas (explicaciones que contienen pocas características).
Las explicaciones creadas con el método de valor Shapley <strong>siempre usan todas las características</strong>.
Los humanos prefieren explicaciones selectivas, como las producidas por LIME.
LIME podría ser la mejor opción para las explicaciones con las que los laicos tienen que lidiar.
Otra solución es <a href="https://github.com/slundberg/shap">SHAP</a> presentada por Lundberg y Lee (2016)<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a>, que se basa en el valor de Shapley, pero también puede proporcionar explicaciones con pocas características.</p>
<p>El valor de Shapley devuelve un valor simple por característica, pero <strong>sin modelo de predicción</strong> como LIME.
Esto significa que no se puede usar para hacer declaraciones sobre cambios en la predicción de cambios en la entrada, como:
“Si ganara 300 euros más al año, mi puntaje de crédito aumentaría en 5 puntos”.</p>
<p>Otra desventaja es que <strong>necesitas acceso a los datos</strong> si deseas calcular el valor de Shapley para una nueva instancia de datos.
No es suficiente acceder a la función de predicción porque necesitas los datos para reemplazar partes de la instancia de interés con valores de instancias de datos extraídos al azar.
Esto solo se puede evitar si puedes crear instancias de datos que se vean como instancias de datos reales pero que no sean instancias reales a partir de los datos de entrenamiento.</p>
<p>Al igual que muchos otros métodos de interpretación basados en permutación, el método del valor de Shapley sufre de <strong>inclusión de instancias de datos poco realistas</strong> cuando las características están correlacionadas.
Para simular que falta un valor de característica en una coalición, marginalizamos la característica.
Esto se logra mediante el muestreo de valores de la distribución marginal de la entidad.
Esto está bien siempre que las características sean independientes.
Cuando las características dependen, entonces podríamos probar valores de características que no tienen sentido para esta instancia.
Pero los usaríamos para calcular el valor Shapley de la entidad.
Que yo sepa, no hay investigación sobre lo que eso significa para los valores de Shapley, ni una sugerencia sobre cómo solucionarlo.
Una solución podría ser permutar características correlacionadas juntas y obtener un valor mutuo de Shapley para ellas.
O el procedimiento de muestreo podría tener que ajustarse para tener en cuenta la dependencia de las características.</p>
</div>
<div id="software-y-alternativas-5" class="section level3">
<h3><span class="header-section-number">5.9.6</span> Software y alternativas</h3>
<p>Los valores de Shapley se implementan en el paquete <code>iml</code> R.</p>
<p>SHAP, un método de estimación alternativo para los valores de Shapley, se presenta en el <a href="shap.html#shap">próximo capítulo</a>.</p>
<p>Otro enfoque se llama breakDown, que se implementa en el paquete <code>breakDown</code>.
BreakDown también muestra las contribuciones de cada característica a la predicción, pero las calcula paso a paso.
Reutilicemos la analogía del juego:
Comenzamos con un equipo vacío, agregamos el valor de la característica que contribuiría más a la predicción e iteramos hasta que se agreguen todos los valores de la característica.
La contribución de cada valor de característica depende de los valores de característica respectivos que ya están en el “equipo”, que es el gran inconveniente del método breakDown.
Es más rápido que el método de valor Shapley, y para modelos sin interacciones, los resultados son los mismos.</p>

<!--{pagebreak}-->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="40">
<li id="fn40"><p>Shapley, Lloyd S. “A value for n-person games.” Contributions to the Theory of Games 2.28 (1953): 307-317.<a href="shapley.html#fnref40" class="footnote-back">↩</a></p></li>
<li id="fn41"><p>Štrumbelj, Erik, and Igor Kononenko. “Explaining prediction models and individual predictions with feature contributions.” Knowledge and information systems 41.3 (2014): 647-665.<a href="shapley.html#fnref41" class="footnote-back">↩</a></p></li>
<li id="fn42"><p>Lundberg, Scott M., and Su-In Lee. “A unified approach to interpreting model predictions.” Advances in Neural Information Processing Systems. 2017.<a href="shapley.html#fnref42" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anchors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="shap.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/05.9-agnostic-shapley.Rmd",
"text": "Editar"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
