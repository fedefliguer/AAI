<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introducción | Aprendizaje automatico interpretable</title>
  <meta name="description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introducción | Aprendizaje automatico interpretable" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introducción | Aprendizaje automatico interpretable" />
  
  <meta name="twitter:description" content="Los algoritmos de aprendizaje autom?tico generalmente funcionan como cajas negras y no esta claro como determinan sus decisiones. Este libro es una guia para profesionales para hacer que las decisiones de aprendizaje automatico sean interpretables." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2020-02-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="interpretabilidad.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Bookdown Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#horadelcuento"><i class="fa fa-check"></i><b>1.1</b> Hora del cuento</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#un-rayo-nunca-golpea-dos-veces"><i class="fa fa-check"></i>Un rayo nunca golpea dos veces</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#perder-confianza"><i class="fa fa-check"></i>Perder confianza</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#clips-de-papel-de-fermi"><i class="fa fa-check"></i>Clips de papel de Fermi</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#que-es-el-aprendizaje-automatico"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es el aprendizaje automático?</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#terminología"><i class="fa fa-check"></i><b>1.3</b> Terminología</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretabilidad.html"><a href="interpretabilidad.html"><i class="fa fa-check"></i><b>2</b> Interpretabilidad</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretabilidad.html"><a href="interpretabilidad.html#interpretabilidad-importancia"><i class="fa fa-check"></i><b>2.1</b> Importancia de la interpretabilidad</a></li>
<li class="chapter" data-level="2.2" data-path="interpretabilidad.html"><a href="interpretabilidad.html#taxonomia-de-los-metodos-de-interpretacion"><i class="fa fa-check"></i><b>2.2</b> Taxonomía de los métodos de interpretación</a></li>
<li class="chapter" data-level="2.3" data-path="interpretabilidad.html"><a href="interpretabilidad.html#alcance-de-la-interpretabilidad"><i class="fa fa-check"></i><b>2.3</b> Alcance de la interpretabilidad</a><ul>
<li class="chapter" data-level="2.3.1" data-path="interpretabilidad.html"><a href="interpretabilidad.html#transparencia-del-algoritmo"><i class="fa fa-check"></i><b>2.3.1</b> Transparencia del algoritmo</a></li>
<li class="chapter" data-level="2.3.2" data-path="interpretabilidad.html"><a href="interpretabilidad.html#interpretabilidad-global-y-holistica-del-modelo"><i class="fa fa-check"></i><b>2.3.2</b> Interpretabilidad global y holística del modelo</a></li>
<li class="chapter" data-level="2.3.3" data-path="interpretabilidad.html"><a href="interpretabilidad.html#interpretabilidad-del-modelo-global-en-un-nivel-modular"><i class="fa fa-check"></i><b>2.3.3</b> Interpretabilidad del modelo global en un nivel modular</a></li>
<li class="chapter" data-level="2.3.4" data-path="interpretabilidad.html"><a href="interpretabilidad.html#interpretabilidad-local-para-una-unica-prediccion"><i class="fa fa-check"></i><b>2.3.4</b> Interpretabilidad local para una única predicción</a></li>
<li class="chapter" data-level="2.3.5" data-path="interpretabilidad.html"><a href="interpretabilidad.html#interpretabilidad-local-para-un-grupo-de-predicciones"><i class="fa fa-check"></i><b>2.3.5</b> Interpretabilidad local para un grupo de predicciones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="interpretabilidad.html"><a href="interpretabilidad.html#evaluacion-de-la-interpretabilidad"><i class="fa fa-check"></i><b>2.4</b> Evaluación de la interpretabilidad</a></li>
<li class="chapter" data-level="2.5" data-path="interpretabilidad.html"><a href="interpretabilidad.html#properties"><i class="fa fa-check"></i><b>2.5</b> Propiedades de las explicaciones</a></li>
<li class="chapter" data-level="2.6" data-path="interpretabilidad.html"><a href="interpretabilidad.html#amigables"><i class="fa fa-check"></i><b>2.6</b> Explicaciones amigables para los humanos</a><ul>
<li class="chapter" data-level="2.6.1" data-path="interpretabilidad.html"><a href="interpretabilidad.html#que-es-una-explicacion"><i class="fa fa-check"></i><b>2.6.1</b> ¿Qué es una explicación?</a></li>
<li class="chapter" data-level="2.6.2" data-path="interpretabilidad.html"><a href="interpretabilidad.html#buenaexplicación"><i class="fa fa-check"></i><b>2.6.2</b> ¿Qué es una buena explicación?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conjuntosdedatos.html"><a href="conjuntosdedatos.html"><i class="fa fa-check"></i><b>3</b> Conjuntos de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="conjuntosdedatos.html"><a href="conjuntosdedatos.html#bike-data"><i class="fa fa-check"></i><b>3.1</b> Alquiler de bicicletas (Regresión)</a></li>
<li class="chapter" data-level="3.2" data-path="conjuntosdedatos.html"><a href="conjuntosdedatos.html#spam-data"><i class="fa fa-check"></i><b>3.2</b> Comentarios de spam de YouTube (clasificación de texto)</a></li>
<li class="chapter" data-level="3.3" data-path="conjuntosdedatos.html"><a href="conjuntosdedatos.html#cervical"><i class="fa fa-check"></i><b>3.3</b> Factores de riesgo para el cáncer de cuello uterino (Clasificación)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje automatico interpretable</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introducción</h1>
<p>Este libro te explica cómo hacer que los modelos de aprendizaje automático (supervisados) sean interpretables.
Los capítulos contienen algunas fórmulas matemáticas, pero deberías poder comprender las ideas detrás de los métodos, incluso sin las fórmulas.
Este libro no es para personas que intentan aprender el aprendizaje automático desde cero.
Si sos nuevo en el aprendizaje automático, hay muchos libros y otros recursos para aprender los conceptos básicos.
Recomiendo el libro “Los elementos del aprendizaje estadístico” de Hastie, Tibshirani y Friedman (2009) <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> y <a href="https://www.coursera.org/learn/machine-learning">el curso en línea “Machine Learning” de Andrew Ng</a> en la plataforma de aprendizaje en línea coursera.com para comenzar con el aprendizaje automático.
¡Tanto el libro como el curso están disponibles de forma gratuita!</p>
<p>Se publican nuevos métodos para la interpretación de modelos de aprendizaje automático a una velocidad vertiginosa.
Mantenerse al día con todo lo que se publica sería una locura y simplemente imposible.
Es por eso que no encontrarás los métodos más novedosos y sofisticados en este libro, sino los métodos establecidos y los conceptos básicos de la capacidad de interpretación del aprendizaje automático.
Estos conceptos básicos te preparan para hacer que los modelos de aprendizaje automático sean interpretables.
La internalización de los conceptos básicos, además, te permitirá comprender y evaluar mejor cualquier documento nuevo sobre interpretabilidad publicado en <a href="https://arxiv.org/">arxiv.org</a> en los últimos 5 minutos desde que comenzaste a leer este libro (podría estar exagerando la tasa de publicación).</p>
<p>Este libro comienza con algunas <a href="intro.html#horadelcuento">historias cortas</a> (distópicas) que no son necesarias para entender el libro, pero con suerte te entretendrán y te harán pensar.
Luego, el libro explora los conceptos de <a href="interpretabilidad.html#interpretabilidad">interpretabilidad del aprendizaje automático</a>.
Discutiremos cuándo la interpretabilidad es importante y qué diferentes tipos de explicaciones hay.
Los términos utilizados a lo largo de todo el libro se pueden consultar en el <a href="intro.html#terminología">Capítulo de terminología</a>.
La mayoría de los modelos y métodos explicados se presentan utilizando ejemplos de datos reales que se describen en el <a href="conjuntosdedatos.html#conjuntosdedatos">Capítulo de conuntos de datos</a>.
Una forma de hacer que el aprendizaje automático sea interpretable es usar <a href="#simple">modelos interpretables</a>, como modelos lineales o árboles de decisión.
La otra opción es el uso de <a href="#agnóstico">herramientas de interpretación modelo-agnósticas</a> que se pueden aplicar a cualquier modelo supervisado de aprendizaje automático.
El capítulo Métodos modelo-agnósticos trata con métodos tales como gráficas de dependencia parcial (PDP) e importancia de la característica de permutación.
Los métodos modelo-agnósticos funcionan cambiando la entrada del modelo de aprendizaje automático y midiendo los cambios en la salida de predicción.
Los métodos independientes al modelo que devuelven observaciones como explicaciones se analizan en el capítulo <a href="#basadoenejemplos">Explicaciones basadas en ejemplos</a>.
Los métodos independientes al modelo se pueden diferenciar aún más, en función de si explican el comportamiento global del modelo en todas las observaciones o si explican predicciones individuales.
Los siguientes métodos explican el comportamiento general del modelo: <a href="#pdp">Gráficos de dependencia parcial</a>, <a href="#ale">Efectos locales acumulados</a>, <a href="#interacción">Interacción de características</a>, <a href="#importanciadecaracterísticas">Importancia de características</a> , <a href="#global">Modelos sustitutos globales</a> y <a href="#proto">Prototipos y críticas</a>.
Para explicar las predicciones individuales, en cambio, tenemos <a href="#LIME">Modelos sustitutos locales</a>, <a href="#shapley">Explicaciones del valor de Shapley</a>, <a href="#contrafactual">Explicaciones contrafactuales</a> (y estrechamente relacionados: <a href="#adversarial">Ejemplos adversos</a>).
Algunos métodos se pueden usar para explicar ambos aspectos del comportamiento del modelo, tanto el carácter global como las predicciones individuales: <a href="#ICE">Expectativa condicional individual</a> e <a href="#influyente">Instancias influyentes</a>.</p>
<p>El libro termina con una perspectiva optimista sobre cómo podría ser <a href="#futuro">el futuro del aprendizaje automático interpretable</a>.</p>
<p>Podés leer el libro de principio a fin o saltar directamente a los métodos que le interesen.</p>
<p>¡Espero que disfrutes la lectura!</p>

<p>﻿
<!--{pagebreak}--></p>
<div id="horadelcuento" class="section level2">
<h2><span class="header-section-number">1.1</span> Hora del cuento</h2>
<p>Comenzaremos con algunas historias cortas.
Cada historia es una llamada algo exagerada para el aprendizaje automático interpretable.
Si tenés prisa, puede saltear las historias.
Si querés entretenerte y (des)motivarte, ¡sigue leyendo!</p>
<p>El formato está inspirado en los cuentos técnicos de Jack Clark en su <a href="https://jack-clark.net/">Boletín informativo Importación AI</a>.
Si te gustan este tipo de historias o si estás interesado en la inteligencia artificial, te recomiendo que te registres.</p>
<div id="un-rayo-nunca-golpea-dos-veces" class="section level3 unnumbered">
<h3>Un rayo nunca golpea dos veces</h3>
<p><strong>2030: un laboratorio médico en Suiza</strong></p>
<p><img src="images/hospital.jpg" width="638" /></p>
<p>“¡Definitivamente no es la peor forma de morir!” Tom resumió, tratando de encontrar algo positivo en la tragedia.
Sacó la bomba del poste intravenoso.
“Simplemente murió por las razones equivocadas”, agregó Lena.
“¡Y ciertamente con la bomba de morfina equivocada!
¡Solo estamos creando más trabajo para nosotros!”, Se quejó Tom mientras desenroscaba la placa posterior de la bomba.
Después de quitar todos los tornillos, levantó la placa y la dejó a un lado.
Conectó un cable al puerto de diagnóstico.
“No solo te quejaste de tener un trabajo, ¿verdad?” Lena le dedicó una sonrisa burlona.
“Por supuesto que no. ¡Nunca!” exclamó con un tono sarcástico.</p>
<p>Arrancó la computadora de la bomba.
Lena enchufó el otro extremo del cable a su tableta.
“Muy bien, los diagnósticos se están ejecutando”, anunció.
“Tengo mucha curiosidad por saber qué salió mal”.
“Ciertamente le disparó a nuestro John Doe al Nirvana.
Fue la alta concentración de este material de morfina.
Hombre. Quiero decir, normalmente, una bomba rota emite muy poco o nada en absoluto.
Pero nunca, ya sabes, algo así”, explicó Tom.
“Lo sé. No tienes que convencerme … Oye, mira eso”. Lena levantó su tableta.
“¿Ves este pico aquí? Esa es la potencia de la mezcla de analgésicos.
¡Mira! Esta línea muestra el nivel de referencia.
El pobre tipo tenía una mezcla de analgésicos en su sistema sanguíneo que podría matarlo 17 veces.
Inyectado por nuestra bomba aquí.
Y aquí …”se deslizó,&quot; aquí puedes ver el momento de la muerte del paciente“.”Entonces, ¿alguna idea de lo que pasó, jefe?&quot; Tom le preguntó a su supervisor.
“Hmm… Los sensores parecen estar bien.
Frecuencia cardíaca, niveles de oxígeno, glucosa, … Los datos se recopilaron como se esperaba.
Algunos valores faltantes en los datos de oxígeno en la sangre, pero eso no es inusual.
Mira aquí.
Los sensores también han detectado la frecuencia cardíaca lenta del paciente y los niveles extremadamente bajos de cortisol causados por el derivado de la morfina y otros agentes bloqueadores del dolor”.
Ella continuó pasando el informe de diagnóstico.
Tom miraba cautivado la pantalla.
Fue su primera investigación de una falla real del dispositivo.</p>
<p>“Ok, aquí está nuestra primera pieza del rompecabezas.
El sistema no pudo enviar una advertencia al canal de comunicación del hospital.
La advertencia se activó, pero se rechazó a nivel de protocolo.
Podría ser culpa nuestra, pero también podría ser culpa del hospital.
Envíe los registros al equipo de IT”, le dijo Lena a Tom.
Tom asintió con los ojos todavía fijos en la pantalla.
Lena continuó:
“Es extraño.
La advertencia también debería haber causado que la bomba se apagara.
Pero obviamente no lo hizo.
Eso debe ser un error.
Algo que control de calidad perdió.
Algo realmente malo.
Tal vez esté relacionado con el problema del protocolo”.
“Entonces, el sistema de emergencia de la bomba de alguna manera se averió, pero ¿por qué la bomba se llenó de bananas e inyectó tanto analgésico en John Doe?” Tom se preguntó.
“Buena pregunta.
Tienes razón.
Dejando de lado la falla de emergencia del protocolo, la bomba no debería haber administrado esa cantidad de medicamento.
El algoritmo debería haberse detenido por sí solo mucho antes, dado el bajo nivel de cortisol y otras señales de advertencia”, explicó Lena.
“¿Quizás algo de mala suerte, como una cosa entre un millón, como ser alcanzado por un rayo?” Tom le preguntó.
“No, Tom.
Si hubiera leído la documentación que le envié, habría sabido que la bomba se entrenó primero en experimentos con animales, luego en humanos, para aprender a inyectar la cantidad perfecta de analgésicos en función de la información sensorial.
El algoritmo de la bomba puede ser opaco y complejo, pero no es aleatorio.
Eso significa que en la misma situación la bomba se comportaría exactamente de la misma manera nuevamente.
Nuestro paciente moriría de nuevo.
Una combinación o interacción no deseada de las entradas sensoriales debe haber desencadenado el comportamiento erróneo de la bomba.
Es por eso que tenemos que profundizar más y descubrir qué sucedió aquí”, explicó Lena.</p>
<p>“Ya veo …”, respondió Tom, perdido en sus pensamientos.
“¿No iba a morir el paciente pronto de todos modos? ¿Por cáncer o algo así?”
Lena asintió mientras leía el informe del análisis.
Tom se levantó y fue a la ventana.
Miró hacia afuera, con los ojos fijos en un punto a la distancia.
“Tal vez la máquina le hizo un favor, ya sabes, al liberarlo del dolor.
No más sufrimiento.
Tal vez simplemente hizo lo correcto.
Como un rayo, pero, ya sabes, uno bueno.
Me refiero a la lotería, pero no al azar.
Pero por una razón.
Si yo fuera la bomba, habría hecho lo mismo”.
Finalmente levantó la cabeza y lo miró.
Seguía mirando algo afuera.
Ambos guardaron silencio por unos momentos.
Lena volvió a bajar la cabeza y continuó el análisis.
“No, Tom. Es un error … Solo un maldito error”.</p>
</div>
<div id="perder-confianza" class="section level3 unnumbered">
<h3>Perder confianza</h3>
<p><strong>2050: una estación de metro en Singapur</strong></p>
<p><img src="images/access-denied.jpg" width="1000" /></p>
<p>Se apresuró a la estación Bishan.
Sus pensamientos ya estaban en el trabajo.
Las pruebas para la nueva arquitectura neuronal deberían completarse por ahora.
Ella dirigió el rediseño del “Sistema fiscal de predicción de afinidad para entidades individuales” del gobierno, que predice si una persona esconderá dinero que debe pagar en impuestos.
Su equipo ha creado una elegante pieza de ingeniería.
Si tiene éxito, el sistema no solo serviría a la oficina de impuestos, sino que también se incorporaría a otros sistemas, como el sistema de alarma contra el terrorismo y el registro comercial.
Un día, el gobierno podría incluso integrar las predicciones en el Civic Trust Score.
El Civic Trust Score estima cuán confiable es una persona.
La estimación afecta cada parte de su vida diaria, como obtener un préstamo o cuánto tiempo tiene que esperar para obtener un nuevo pasaporte.
Mientras bajaba la escalera mecánica, se imaginó cómo se vería una integración del sistema de su equipo en el sistema de puntuación de confianza cívica.</p>
<p>Rutinariamente pasaba la mano por el lector sin reducir su velocidad de marcha.
Su mente estaba ocupada, hasta que sonaron las alarmas en su cerebro.</p>
<p>Demasiado tarde.</p>
<p>Con la nariz primero, corrió hacia la puerta de entrada del metro y cayó con el trasero al suelo.
Se suponía que la puerta se abría … pero no fue así.
Atónita, se levantó y miró la pantalla junto a la puerta.
“Por favor, inténtalo en otro momento”, sugirió una carita sonriente en la pantalla.
Una persona pasó y, ignorándola, pasó la mano sobre el lector.
La puerta se abrió y él entró.
La puerta se cerró de nuevo.
Se limpió la nariz.
Le dolía, pero al menos no sangraba.
Ella trató de abrir la puerta, pero fue rechazada nuevamente.
Fue extraño
Tal vez su cuenta de transporte público no tenía suficiente crédito.
Miró su reloj inteligente para verificar el saldo de la cuenta.</p>
<p>&quot;Inicio de sesión denegado. ¡Comuníquese con su Oficina de asesoramiento para ciudadanos! su reloj le informó.</p>
<p>Una sensación de náuseas la golpeó como un puño en el estómago.
Ella sospechaba lo que había sucedido.
Para confirmar su teoría, abrió “Sniper Guild”, un juego de disparos en primera persona.
La aplicación se cerró de nuevo automáticamente, lo que confirmó su teoría.
Se mareó y volvió a sentarse en el suelo.</p>
<p>Solo había una explicación posible:
Su puntuación de confianza cívica había bajado.
Sustancialmente.
Una pequeña caída significaba inconvenientes menores, como no obtener vuelos de primera clase o tener que esperar un poco más para obtener los documentos oficiales.
Un puntaje de confianza bajo era raro y quien lo tenía estaba clasificado como una amenaza para la sociedad: Una medida para tratar con estas personas era mantenerlas alejadas de lugares públicos como el metro.
El gobierno, además, restringió las transacciones financieras de sujetos con bajos puntajes de confianza cívica.
También comenzaron a monitorear activamente su comportamiento en las redes sociales e incluso llegaron a restringir cierto contenido, como los juegos violentos.
Se había vuelto más difícil aumentar el puntaje de confianza cívica cuanto más bajo era éste. Las personas con un puntaje muy bajo generalmente nunca se recuperaban.</p>
<p>No podía pensar en ninguna razón por la cual su puntuación debería haber caído.
La puntuación se basó en el aprendizaje automático.
El Civic Trust Score System funcionó como un motor bien engrasado que dirigía la sociedad.
El rendimiento del sistema de puntuación de confianza siempre se supervisó de cerca.
El aprendizaje automático había mejorado mucho desde principios de siglo.
Se había vuelto tan eficiente que las decisiones tomadas por el Trust Score System ya no podían ser cuestionadas.
Un sistema infalible.</p>
<p>Rió desesperada.
Sistema infalible.
El sistema rara vez había fallado.
Pero falló.
Ella debe ser uno de esos casos especiales;
un error del sistema;
a partir de ahora un paria.
Nadie se atrevió a cuestionar el sistema.
Estaba demasiado integrado en el gobierno, en la sociedad misma, para ser cuestionado.
En los pocos países democráticos restantes, estaba prohibido formar movimientos antidemocráticos, no porque fueran inherentemente maliciosos, sino porque desestabilizarían el sistema actual.
La misma lógica se aplica a las ahora algocracias.
La crítica en los algoritmos estaba prohibida debido al peligro para el status quo.</p>
<p>La confianza algorítmica era el tejido del orden social.
Por el bien común, se aceptaron tácitamente raras puntuaciones falsas de confianza.
Cientos de otros sistemas de predicción y bases de datos ingresaron al puntaje, lo que hace imposible saber qué causó la caída en su puntaje.
Sintió que un gran agujero oscuro se abría dentro y debajo de ella.
Con horror, miró al vacío.</p>
<p>Su sistema de afinidad fiscal finalmente se integró en el Sistema de puntuación de confianza cívica, pero nunca llegó a saberlo.</p>
</div>
<div id="clips-de-papel-de-fermi" class="section level3 unnumbered">
<h3>Clips de papel de Fermi</h3>
<p><strong>Año 612 AMS (después del asentamiento en Marte): un museo en Marte</strong></p>
<p><img src="images/burnt-earth.jpg" width="1500" /></p>
<p>“La historia es aburrida”, le susurró Xola a su amiga.
Xola, una chica de cabello azul, perseguía uno de los drones del proyector que zumbaba en la habitación con la mano izquierda.
“La historia es importante”, dijo la maestra con voz molesta, mirando a las chicas.
Xola se sonrojó.
No esperaba que su maestra la escuchara.</p>
<p>“Xola, ¿qué acabas de aprender?” la maestra le preguntó.
“¿Que la gente antigua usó todos los recursos del Planeta Terrestre y luego murió?” ella preguntó cuidadosamente.
“No. Calentaron el clima y no fueron las personas, fueron las computadoras y las máquinas. Y es el planeta Tierra, no el planeta Terrestre”, agregó otra chica llamada Lin.
Xola asintió de acuerdo.
Con un toque de orgullo, la maestra sonrió y asintió.
“Ambos tienen razón. ¿Sabes por qué sucedió?”
“¿Porque la gente era miope y codiciosa?” Xola preguntó.
“¡La gente no podía parar sus máquinas!” Espetó Lin.</p>
<p>“Una vez más, ambos tienen razón”, decidió la maestra,
“Pero es mucho más complicado que eso.
La mayoría de las personas en ese momento no sabían lo que estaba sucediendo.
Algunos vieron los cambios drásticos, pero no pudieron revertirlos.
La pieza más famosa de este período es un poema de un autor anónimo.
Captura mejor lo que sucedió en ese momento.
¡Escucha cuidadosamente!”</p>
<p>La maestra comenzó el poema.
Una docena de pequeños drones se reposicionaron frente a los niños y comenzaron a proyectar el video directamente en sus ojos.
Mostraba a una persona en un traje de pie en un bosque con solo tocones de árboles.
La persona comenzó a hablar:</p>
<p><em>Las máquinas computan; las máquinas predicen.</em></p>
<p><em>Somos parte de esto.</em></p>
<p><em>Perseguimos un óptimo entrenado.</em></p>
<p><em>Lo óptimo es unidimensional, local y sin restricciones.</em></p>
<p><em>Silicio y carne, persiguiendo la exponencialidad.</em></p>
<p><em>El crecimiento es nuestra mentalidad.</em></p>
<p><em>Cuando todas las recompensas sean recogidas,</em></p>
<p><em>y sus efectos secundarios descuidados;</em></p>
<p><em>Cuando se extraigan todas las monedas,</em></p>
<p><em>y la naturaleza haya quedado atrás;</em></p>
<p><em>Estaremos en problemas,</em></p>
<p><em>Después de todo, el crecimiento exponencial es una burbuja.</em></p>
<p><em>La tragedia del desarrollo de los comunes,</em></p>
<p><em>Explotando,</em></p>
<p><em>Ante nuestros ojos.</em></p>
<p><em>Cálculos fríos y avaricia helada,</em></p>
<p><em>Llena la tierra de calor.</em></p>
<p><em>Todo se está muriendo,</em></p>
<p><em>Y estamos cumpliendo.</em></p>
<p><em>Al igual que los caballos con anteojeras, corremos la carrera de nuestra propia creación,</em></p>
<p><em>Hacia el gran filtro de la civilización.</em></p>
<p><em>Y así marchamos sin descanso.</em></p>
<p><em>Como somos parte de la máquina.</em></p>
<p><em>Abrazando la entropía.</em></p>
<p>“Un recuerdo oscuro”, dijo la maestra para romper el silencio en la sala.
“Se cargará en su biblioteca.
Tu tarea es memorizarla hasta la próxima semana.”
Xola suspiró.
Ella logró atrapar uno de los pequeños drones.
El dron estaba caliente por la CPU y los motores.
A Xola le gustó cómo le calentó las manos.</p>

<p>﻿
<!--{pagebreak}--></p>
</div>
</div>
<div id="que-es-el-aprendizaje-automatico" class="section level2">
<h2><span class="header-section-number">1.2</span> ¿Qué es el aprendizaje automático?</h2>
<p>El aprendizaje automático es un conjunto de métodos que usan las computadoras para hacer y mejorar predicciones o comportamientos basados en datos.</p>
<p>Por ejemplo, para predecir el valor de una casa, la computadora puede aprender patrones de ventas pasadas de casas.
El libro se centra en el aprendizaje automático supervisado, que cubre todos los problemas de predicción en los que tenemos un conjunto de datos para el que ya conocemos el resultado de interés (por ejemplo, precios anteriores de la vivienda) y queremos predecir el resultado de los nuevos datos.
Se excluyen del aprendizaje supervisado, por ejemplo, las tareas de agrupación (aprendizaje no supervisado) donde no tenemos un resultado específico de interés, pero queremos encontrar grupos de observaciones.
También se excluyen cosas como el aprendizaje por refuerzo, donde un agente aprende a optimizar cierta recompensa actuando en un entorno (por ejemplo, una computadora que juega Tetris).
El objetivo del aprendizaje supervisado es aprender un modelo predictivo que relacione características de los datos (por ejemplo, tamaño de la casa, ubicación, tipo de piso, …) con una salida (por ejemplo, el precio de la casa).
Si el resultado es categórico, el objetivo se llama clasificación, y si es numérico, se llama regresión.
El algoritmo de aprendizaje automático aprende un modelo mediante la estimación de parámetros (como pesos) o estructuras de aprendizaje (como árboles).
El algoritmo se guía por una función de puntuación o pérdida que se minimiza.
En el ejemplo del valor de la vivienda, la máquina minimiza la diferencia entre el precio estimado de la vivienda y el precio previsto.
Un modelo de aprendizaje automático totalmente entrenado se puede utilizar para hacer predicciones para nuevas instancias.</p>
<p>Estimación de precios de la vivienda, recomendaciones de productos, detección de letreros, predicción de incumplimiento crediticio y detección de fraude:
Todos estos ejemplos tienen en común que pueden resolverse mediante el aprendizaje automático.
Las tareas son diferentes, pero el enfoque es el mismo:
Paso 1: recopilación de datos.
Mientras más, mejor.
Los datos deben contener el resultado que desea predecir e información adicional a partir de la cual realizar la predicción.
Para un detector de letrero de calle (“¿Hay un letrero de calle en la imagen?”), debes recopilar imágenes de la calle y etiquetar si un letrero de calle es visible o no.
Para un predictor de incumplimiento de crédito, necesitas datos pasados sobre préstamos reales, información sobre si los clientes estaban en incumplimiento con sus préstamos y datos que lo ayudarán a hacer predicciones, como ingresos, incumplimientos de créditos pasados, etc.
Para un programa de estimación automática del valor de la vivienda, podés recopilar datos de ventas de viviendas anteriores e información sobre los bienes inmuebles, como el tamaño, la ubicación, etc.
Paso 2: ingreso de esta información en un algoritmo de aprendizaje automático que genera un modelo de detector de signos, un modelo de calificación crediticia o un estimador del valor de la vivienda.
Paso 3: uso del modelo con nuevos datos.
Integrar el modelo en un producto o proceso, como un automóvil sin conductor, un proceso de solicitud de crédito o un sitio web del mercado inmobiliario.</p>
<p>Las máquinas superan a los humanos en muchas tareas, como jugar al ajedrez (o más recientemente Go) o predecir el clima.
Incluso si la máquina es tan buena como un ser humano o un poco peor en una tarea, sigue habiendo grandes ventajas en términos de velocidad, reproducibilidad y escala.
Una vez implementado, un modelo de aprendizaje automático puede completar una tarea mucho más rápido que los humanos, ofrece resultados consistentes y se puede copiar infinitamente.
La replicación de un modelo de aprendizaje automático en otra máquina es rápida y barata.
El entrenamiento de un humano para una tarea puede llevar décadas (especialmente cuando son jóvenes) y es muy costoso.
Una desventaja importante del uso del aprendizaje automático es que los conocimientos sobre los datos y la tarea que resuelve la máquina están ocultos en modelos cada vez más complejos.
Necesita millones de números para describir una red neuronal profunda, y no hay forma de entender el modelo en su totalidad.
Otros modelos, como el random forest, consisten en cientos de árboles de decisión que “votan” por predicciones.
Para comprender cómo se tomó la decisión, debería examinar los votos y las estructuras de cada uno de los cientos de árboles.
Eso simplemente no funciona, no importa cuán inteligente sea o cuán buena sea su memoria de trabajo.
Los modelos con mejor rendimiento son a menudo mezclas de varios modelos (también llamados conjuntos) imposibles de interpretar, aún bajo la posibilidad de que cada modelo se pudiera interpretar.
Si te enfocas solo en el rendimiento, obtendrás automáticamente modelos cada vez más opacos.
Solo echa un vistazo a <a href="http://blog.kaggle.com/">entrevistas con ganadores en la plataforma de competencia de aprendizaje automático kaggle.com</a>:
Los modelos ganadores eran en su mayoría conjuntos de modelos o modelos muy complejos, como árboles potenciados o redes neuronales profundas.</p>
<!--{pagebreak}-->
</div>
<div id="terminología" class="section level2">
<h2><span class="header-section-number">1.3</span> Terminología</h2>
<p>Para evitar confusiones debido a la ambigüedad, aquí hay algunas definiciones de los términos utilizados en este libro:</p>
<p>Un <strong>Algoritmo</strong> es un conjunto de reglas que una máquina sigue para lograr un objetivo particular<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.
Un algoritmo puede considerarse como una receta que define las entradas, la salida y todos los pasos necesarios para pasar de las entradas a la salida.
Las recetas de cocción son algoritmos en los que los ingredientes son las entradas, la comida cocida es la salida y los pasos de preparación y cocción son las instrucciones del algoritmo.</p>
<p><strong>Aprendizaje automático</strong> es un conjunto de métodos que permiten a las computadoras aprender de los datos para hacer y mejorar predicciones (por ejemplo, cáncer, ventas semanales, incumplimiento de crédito).
El aprendizaje automático es un cambio de paradigma de la “programación normal”, donde todas las instrucciones se deben dar explícitamente a la computadora a la “programación indirecta” que se realiza mediante el suministro de datos.</p>
<p><img src="images/programing-ml.png" width="660" /></p>
<p>Un <strong>Aprendiz</strong> o <strong>Algoritmo de aprendizaje automático</strong> es el programa utilizado para aprender un modelo de aprendizaje automático a partir de datos.
Otro nombre es “inductor” (por ejemplo, “inductor de árbol”).</p>
<p>Un <strong>Modelo de aprendizaje automático</strong> es el programa aprendido que asigna entradas a predicciones.
Esto puede ser un conjunto de pesos para un modelo lineal o para una red neuronal.
Otros nombres para la palabra bastante inespecífica “modelo” son “predictor” o, según la tarea, “clasificador” o “modelo de regresión”.
En las fórmulas, el modelo de aprendizaje automático entrenado se llama <span class="math inline">\(\hat{f}\)</span> o <span class="math inline">\(\hat{f}(x)\)</span>.</p>
<div class="figure"><span id="fig:learner-definition"></span>
<img src="images/learner.png" alt="A learner learns a model from labeled training data. The model is used to make predictions." width="500" />
<p class="caption">
FIGURE 1.1: A learner learns a model from labeled training data. The model is used to make predictions.
</p>
</div>
<p>Un <strong>Modelo de caja negra</strong> es un sistema que no revela sus mecanismos internos.
En el aprendizaje automático, la “caja negra” describe modelos que no se pueden entender al observar sus parámetros (por ejemplo, una red neuronal).
El opuesto de una caja negra a veces se denomina <strong>caja blanca</strong>, y es llamada en este libro como <a href="#simple">modelo interpretable</a>.
<a href="#agnóstico">Los métodos modelo-agnósticos</a> para la interpretabilidad tratan los modelos de aprendizaje automático como cajas negras, incluso si no lo son.</p>
<p><img src="images/iml.png" width="600" /></p>
<p><strong>Aprendizaje automático interpretable</strong> se refiere a métodos y modelos que hacen que el comportamiento y las predicciones de los sistemas de aprendizaje automático sean comprensibles para los humanos.</p>
<p>Un <strong>conjunto de datos </strong> es una tabla con los datos de los cuales la máquina aprende.
El conjunto de datos contiene las características y el objetivo a predecir.
Cuando se usa para el aprendizaje de un modelo, el conjunto de datos se denomina datos de entrenamiento.</p>
<p>Una <strong>observación</strong> es una fila en el conjunto de datos.
Otros nombres para ‘observación’ son: punto (datos), ejemplo, instancia.
Una instancia consta de los valores de característica <span class="math inline">\(x^{(i)}\)</span> y, si se conoce, el resultado objetivo <span class="math inline">\(y_i\)</span>.</p>
<p>Las <strong>características</strong> son las entradas utilizadas para la predicción o clasificación.
Una característica es una columna en el conjunto de datos.
A lo largo del libro, se supone que las características son interpretables, lo que significa que es fácil entender lo que significan, como la temperatura en un día determinado o la altura de una persona.
La interpretabilidad de las características es una gran suposición, pero si es difícil entender las características de entrada, es aún más difícil entender lo que hace el modelo.
La matriz con todas las características se llama X y <span class="math inline">\(x^{(i)}\)</span> para instancia individual.
El vector de una sola característica para todas las instancias es <span class="math inline">\(x_j\)</span> y el valor para la característica j y la instancia i es <span class="math inline">\(x^{(i)}_j\)</span>.</p>
<p>El <strong>Objetivo (o target)</strong> es la columna que la máquina aprende a predecir.
En las fórmulas matemáticas, el objetivo generalmente se llama y o <span class="math inline">\(y_i\)</span> para una sola instancia.</p>
<p>Una <strong>Tarea de aprendizaje automático</strong> es la combinación de un conjunto de datos con características y un objetivo.
Dependiendo del tipo de objetivo, la tarea puede ser, por ejemplo, clasificación, regresión, análisis de supervivencia, agrupamiento o detección de valores atípicos.</p>
<p>La <strong>Predicción</strong> es el valor que el modelo de aprendizaje automático pronostica, en función de las características dadas.
En este libro, la predicción del modelo se denota por <span class="math inline">\(\hat{f}(x^{(i)})\)</span> o <span class="math inline">\(\hat{y}\)</span>.</p>

<p>﻿<code>{r, message = FALSE, warning = FALSE, echo = FALSE} devtools::load_all()</code></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Friedman, Jerome, Trevor Hastie y Robert Tibshirani. “Los elementos del aprendizaje estadístico”. www.web.stanford.edu/~hastie/ElemStatLearn/ (2009).<a href="intro.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>“Definición de algoritmo”. <a href="https://www.merriam-webster.com/dictionary/algorithm" class="uri">https://www.merriam-webster.com/dictionary/algorithm</a>. (2017)<a href="intro.html#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interpretabilidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
